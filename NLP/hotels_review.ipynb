{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Load the hotel reviews from CSV\r\n",
    "import pandas as pd\r\n",
    "import time\r\n",
    "# importing time so the start and end time can be used to calculate file loading time\r\n",
    "print(\"Loading data file now, this could take a while depending on file size\")\r\n",
    "start = time.time()\r\n",
    "# df is 'DataFrame' - make sure you downloaded the file to the data folder\r\n",
    "df = pd.read_csv('Hotel_Reviews.csv')\r\n",
    "end = time.time()\r\n",
    "print(\"Loading took \" + str(round(end - start, 2)) + \" seconds\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading data file now, this could take a while depending on file size\n",
      "Loading took 5.33 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(515738, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Calculate the frequency count for reviewer nationalities:\r\n",
    "\r\n",
    "# How many distinct values are there for the column Reviewer_Nationality and what are they?\r\n",
    "# What reviewer nationality is the most common in the dataset (print country and number of reviews)?\r\n",
    "\r\n",
    "# value_counts() creates a Series object that has index and values in this case, the country and the frequency they occur in reviewer nationality\r\n",
    "nationality_freq = df[\"Reviewer_Nationality\"].value_counts()\r\n",
    "print(\"There are \" + str(nationality_freq.size) + \" different nationalities\")\r\n",
    "# print first and last rows of the Series. Change to nationality_freq.to_string() to print all of the data\r\n",
    "print(nationality_freq) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 227 different nationalities\n",
      " United Kingdom               245246\n",
      " United States of America      35437\n",
      " Australia                     21686\n",
      " Ireland                       14827\n",
      " United Arab Emirates          10235\n",
      "                               ...  \n",
      " Northern Mariana Islands          1\n",
      " Svalbard Jan Mayen                1\n",
      " Anguilla                          1\n",
      " Tuvalu                            1\n",
      " Guinea                            1\n",
      "Name: Reviewer_Nationality, Length: 227, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# What are the next top 10 most frequently found nationalities, and their frequency count?\r\n",
    "\r\n",
    "print(\"The highest frequency reviewer nationality is \" + str(nationality_freq.index[0]).strip() + \" with \" + str(nationality_freq[0]) + \" reviews.\")\r\n",
    "# Notice there is a leading space on the values, strip() removes that for printing\r\n",
    "# What is the top 10 most common nationalities and their frequencies?\r\n",
    "print(\"The next 10 highest frequency reviewer nationalities are:\")\r\n",
    "print(nationality_freq[1:11].to_string())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The highest frequency reviewer nationality is United Kingdom with 245246 reviews.\n",
      "The next 10 highest frequency reviewer nationalities are:\n",
      " United States of America     35437\n",
      " Australia                    21686\n",
      " Ireland                      14827\n",
      " United Arab Emirates         10235\n",
      " Saudi Arabia                  8951\n",
      " Netherlands                   8772\n",
      " Switzerland                   8678\n",
      " Germany                       7941\n",
      " Canada                        7894\n",
      " France                        7296\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# What was the most frequently reviewed hotel for the top 10 nationalities\r\n",
    "# Normally with pandas you will avoid an explicit loop, but wanted to show creating a new dataframe using criteria (don't do this with large amounts of data because it could be very slow)\r\n",
    "for nat in nationality_freq[:10].index:\r\n",
    "   # First, extract all the rows that match the criteria into a new dataframe\r\n",
    "   nat_df = df[df[\"Reviewer_Nationality\"] == nat]   \r\n",
    "   # Now get the hotel freq\r\n",
    "   freq = nat_df[\"Hotel_Name\"].value_counts()\r\n",
    "   print(\"The most reviewed hotel for \" + str(nat).strip() + \" was \" + str(freq.index[0]) + \" with \" + str(freq[0]) + \" reviews.\") "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The most reviewed hotel for United Kingdom was Britannia International Hotel Canary Wharf with 3833 reviews.\n",
      "The most reviewed hotel for United States of America was Hotel Esther a with 423 reviews.\n",
      "The most reviewed hotel for Australia was Park Plaza Westminster Bridge London with 167 reviews.\n",
      "The most reviewed hotel for Ireland was Copthorne Tara Hotel London Kensington with 239 reviews.\n",
      "The most reviewed hotel for United Arab Emirates was Millennium Hotel London Knightsbridge with 129 reviews.\n",
      "The most reviewed hotel for Saudi Arabia was The Cumberland A Guoman Hotel with 142 reviews.\n",
      "The most reviewed hotel for Netherlands was Jaz Amsterdam with 97 reviews.\n",
      "The most reviewed hotel for Switzerland was Hotel Da Vinci with 97 reviews.\n",
      "The most reviewed hotel for Germany was Hotel Da Vinci with 86 reviews.\n",
      "The most reviewed hotel for Canada was St James Court A Taj Hotel London with 61 reviews.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# How many reviews are there per hotel (frequency count of hotel) in the dataset?\r\n",
    "\r\n",
    "# First create a new dataframe based on the old one, removing the uneeded columns\r\n",
    "hotel_freq_df = df.drop([\"Hotel_Address\", \"Additional_Number_of_Scoring\", \"Review_Date\", \"Average_Score\", \"Reviewer_Nationality\", \"Negative_Review\", \"Review_Total_Negative_Word_Counts\", \"Positive_Review\", \"Review_Total_Positive_Word_Counts\", \"Total_Number_of_Reviews_Reviewer_Has_Given\", \"Reviewer_Score\", \"Tags\", \"days_since_review\", \"lat\", \"lng\"], axis = 1)\r\n",
    "\r\n",
    "# Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found\r\n",
    "hotel_freq_df['Total_Reviews_Found'] = hotel_freq_df.groupby('Hotel_Name').transform('count')\r\n",
    "\r\n",
    "# Get rid of all the duplicated rows\r\n",
    "hotel_freq_df = hotel_freq_df.drop_duplicates(subset = [\"Hotel_Name\"])\r\n",
    "display(hotel_freq_df) "
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Total_Reviews_Found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>1403</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>K K Hotel George</td>\n",
       "      <td>1831</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Apex Temple Court Hotel</td>\n",
       "      <td>2619</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>The Park Grand London Paddington</td>\n",
       "      <td>4380</td>\n",
       "      <td>1770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>Monhotel Lounge SPA</td>\n",
       "      <td>171</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511962</th>\n",
       "      <td>Suite Hotel 900 m zur Oper</td>\n",
       "      <td>3461</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512401</th>\n",
       "      <td>Hotel Amadeus</td>\n",
       "      <td>717</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512545</th>\n",
       "      <td>The Berkeley</td>\n",
       "      <td>232</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512645</th>\n",
       "      <td>Holiday Inn London Kensington</td>\n",
       "      <td>5945</td>\n",
       "      <td>2768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515413</th>\n",
       "      <td>Atlantis Hotel Vienna</td>\n",
       "      <td>2823</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1492 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Hotel_Name  Total_Number_of_Reviews  \\\n",
       "0                            Hotel Arena                     1403   \n",
       "405                     K K Hotel George                     1831   \n",
       "971              Apex Temple Court Hotel                     2619   \n",
       "2008    The Park Grand London Paddington                     4380   \n",
       "3778                 Monhotel Lounge SPA                      171   \n",
       "...                                  ...                      ...   \n",
       "511962        Suite Hotel 900 m zur Oper                     3461   \n",
       "512401                     Hotel Amadeus                      717   \n",
       "512545                      The Berkeley                      232   \n",
       "512645     Holiday Inn London Kensington                     5945   \n",
       "515413             Atlantis Hotel Vienna                     2823   \n",
       "\n",
       "        Total_Reviews_Found  \n",
       "0                       405  \n",
       "405                     566  \n",
       "971                    1037  \n",
       "2008                   1770  \n",
       "3778                     35  \n",
       "...                     ...  \n",
       "511962                  439  \n",
       "512401                  144  \n",
       "512545                  100  \n",
       "512645                 2768  \n",
       "515413                  325  \n",
       "\n",
       "[1492 rows x 3 columns]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# While there is an Average_Score column for each hotel in the dataset, you can also calculate an average score (getting the average of all reviewer scores in the dataset for each hotel). \r\n",
    "# Add a new column to your dataframe with the column header Calc_Average_Score that contains that calculated average. Print out the columns Hotel_Name, Average_Score, and Calc_Average_Score.\r\n",
    "\r\n",
    "# define a function that takes a row and performs some calculation with it\r\n",
    "def get_difference_review_avg(row):\r\n",
    "  return row[\"Average_Score\"] - row[\"Calc_Average_Score\"]\r\n",
    "\r\n",
    "# 'mean' is mathematical word for 'average'\r\n",
    "df['Calc_Average_Score'] = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)\r\n",
    "\r\n",
    "# Add a new column with the difference between the two average scores\r\n",
    "df[\"Average_Score_Difference\"] = df.apply(get_difference_review_avg, axis = 1)\r\n",
    "\r\n",
    "# Create a df without all the duplicates of Hotel_Name (so only 1 row per hotel)\r\n",
    "review_scores_df = df.drop_duplicates(subset = [\"Hotel_Name\"])\r\n",
    "\r\n",
    "# Sort the dataframe to find the lowest and highest average score difference\r\n",
    "review_scores_df = review_scores_df.sort_values(by=[\"Average_Score_Difference\"])\r\n",
    "\r\n",
    "display(review_scores_df[[\"Average_Score_Difference\", \"Average_Score\", \"Calc_Average_Score\", \"Hotel_Name\"]])"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average_Score_Difference</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Calc_Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495945</th>\n",
       "      <td>-0.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Best Western Hotel Astoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111027</th>\n",
       "      <td>-0.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>Hotel Stendhal Place Vend me Paris MGallery by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43688</th>\n",
       "      <td>-0.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Mercure Paris Porte d Orleans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178253</th>\n",
       "      <td>-0.7</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Renaissance Paris Vendome Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218258</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Hotel Royal Elys es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201776</th>\n",
       "      <td>0.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Mercure Paris Op ra Faubourg Montmartre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22189</th>\n",
       "      <td>0.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Holiday Inn Paris Montparnasse Pasteur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68936</th>\n",
       "      <td>0.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Villa Eugenie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250308</th>\n",
       "      <td>0.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>MARQUIS Faubourg St Honor Relais Ch teaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>1.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Kube Hotel Ice Bar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1492 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Average_Score_Difference  Average_Score  Calc_Average_Score  \\\n",
       "495945                      -0.8            7.7                 8.5   \n",
       "111027                      -0.7            8.8                 9.5   \n",
       "43688                       -0.7            7.5                 8.2   \n",
       "178253                      -0.7            7.9                 8.6   \n",
       "218258                      -0.5            7.0                 7.5   \n",
       "...                          ...            ...                 ...   \n",
       "201776                       0.7            7.5                 6.8   \n",
       "22189                        0.8            7.1                 6.3   \n",
       "68936                        0.9            6.8                 5.9   \n",
       "250308                       0.9            8.6                 7.7   \n",
       "3813                         1.3            7.2                 5.9   \n",
       "\n",
       "                                               Hotel_Name  \n",
       "495945                         Best Western Hotel Astoria  \n",
       "111027  Hotel Stendhal Place Vend me Paris MGallery by...  \n",
       "43688                       Mercure Paris Porte d Orleans  \n",
       "178253                    Renaissance Paris Vendome Hotel  \n",
       "218258                                Hotel Royal Elys es  \n",
       "...                                                   ...  \n",
       "201776            Mercure Paris Op ra Faubourg Montmartre  \n",
       "22189              Holiday Inn Paris Montparnasse Pasteur  \n",
       "68936                                       Villa Eugenie  \n",
       "250308          MARQUIS Faubourg St Honor Relais Ch teaux  \n",
       "3813                                   Kube Hotel Ice Bar  \n",
       "\n",
       "[1492 rows x 4 columns]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Calculate and print out how many rows have column Positive_Review values of \"No Positive\" and Negative_Review values of \"No Negative\"\r\n",
    "\r\n",
    "# with lambdas:\r\n",
    "start = time.time()\r\n",
    "no_negative_reviews = df.apply(lambda x: True if x['Negative_Review'] == \"No Negative\" else False , axis=1)\r\n",
    "print(\"Number of No Negative reviews: \" + str(len(no_negative_reviews[no_negative_reviews == True].index)))\r\n",
    "\r\n",
    "no_positive_reviews = df.apply(lambda x: True if x['Positive_Review'] == \"No Positive\" else False , axis=1)\r\n",
    "print(\"Number of No Positive reviews: \" + str(len(no_positive_reviews[no_positive_reviews == True].index)))\r\n",
    "\r\n",
    "both_no_reviews = df.apply(lambda x: True if x['Negative_Review'] == \"No Negative\" and x['Positive_Review'] == \"No Positive\" else False , axis=1)\r\n",
    "print(\"Number of both No Negative and No Positive reviews: \" + str(len(both_no_reviews[both_no_reviews == True].index)))\r\n",
    "end = time.time()\r\n",
    "print(\"Lambdas took \" + str(round(end - start, 2)) + \" seconds\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of No Negative reviews: 127890\n",
      "Number of No Positive reviews: 35946\n",
      "Number of both No Negative and No Positive reviews: 127\n",
      "Lambdas took 47.06 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# without lambdas (using a mixture of notations to show you can use both)\r\n",
    "start = time.time()\r\n",
    "no_negative_reviews = sum(df.Negative_Review == \"No Negative\")\r\n",
    "print(\"Number of No Negative reviews: \" + str(no_negative_reviews))\r\n",
    "\r\n",
    "no_positive_reviews = sum(df[\"Positive_Review\"] == \"No Positive\")\r\n",
    "print(\"Number of No Positive reviews: \" + str(no_positive_reviews))\r\n",
    "\r\n",
    "both_no_reviews = sum((df.Negative_Review == \"No Negative\") & (df.Positive_Review == \"No Positive\"))\r\n",
    "print(\"Number of both No Negative and No Positive reviews: \" + str(both_no_reviews))\r\n",
    "\r\n",
    "end = time.time()\r\n",
    "print(\"Sum took \" + str(round(end - start, 2)) + \" seconds\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of No Negative reviews: 127890\n",
      "Number of No Positive reviews: 35946\n",
      "Number of both No Negative and No Positive reviews: 127\n",
      "Sum took 1.18 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Initial column processing\r\n",
    "\r\n",
    "# Drop lat and lng\r\n",
    "# Replace Hotel_Address values with the following values (if the address contains the same of the city and the country, change it to just the city and the country).\r\n",
    "# These are the only cities and countries in the dataset:\r\n",
    "# Amsterdam, Netherlands\r\n",
    "# Barcelona, Spain\r\n",
    "# London, United Kingdom\r\n",
    "# Milan, Italy\r\n",
    "# Paris, France\r\n",
    "# Vienna, Austria\r\n",
    "\r\n",
    "def replace_address(row):\r\n",
    "    if \"Netherlands\" in row[\"Hotel_Address\"]:\r\n",
    "        return \"Amsterdam, Netherlands\"\r\n",
    "    elif \"Barcelona\" in row[\"Hotel_Address\"]:\r\n",
    "        return \"Barcelona, Spain\"\r\n",
    "    elif \"United Kingdom\" in row[\"Hotel_Address\"]:\r\n",
    "        return \"London, United Kingdom\"\r\n",
    "    elif \"Milan\" in row[\"Hotel_Address\"]:        \r\n",
    "        return \"Milan, Italy\"\r\n",
    "    elif \"France\" in row[\"Hotel_Address\"]:\r\n",
    "        return \"Paris, France\"\r\n",
    "    elif \"Vienna\" in row[\"Hotel_Address\"]:\r\n",
    "        return \"Vienna, Austria\" \r\n",
    "\r\n",
    "# Replace all the addresses with a shortened, more useful form\r\n",
    "df[\"Hotel_Address\"] = df.apply(replace_address, axis = 1)\r\n",
    "# The sum of the value_counts() should add up to the total number of reviews\r\n",
    "print(df[\"Hotel_Address\"].value_counts())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "London, United Kingdom    262301\n",
      "Barcelona, Spain           60149\n",
      "Paris, France              59928\n",
      "Amsterdam, Netherlands     57214\n",
      "Vienna, Austria            38939\n",
      "Milan, Italy               37207\n",
      "Name: Hotel_Address, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "display(df.groupby(\"Hotel_Address\").agg({\"Hotel_Name\": \"nunique\"}))"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amsterdam, Netherlands</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barcelona, Spain</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London, United Kingdom</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milan, Italy</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paris, France</th>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vienna, Austria</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Hotel_Name\n",
       "Hotel_Address                     \n",
       "Amsterdam, Netherlands         105\n",
       "Barcelona, Spain               211\n",
       "London, United Kingdom         400\n",
       "Milan, Italy                   162\n",
       "Paris, France                  458\n",
       "Vienna, Austria                158"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Process Hotel Meta-review columns\r\n",
    "# Drop Additional_Number_of_Scoring\r\n",
    "# Replace Total_Number_of_Reviews with the total number of reviews for that hotel that are actually in the dataset\r\n",
    "# Replace Average_Score with our own calculated score\r\n",
    "\r\n",
    "# Drop `Additional_Number_of_Scoring`\r\n",
    "df.drop([\"Additional_Number_of_Scoring\"], axis = 1, inplace=True)\r\n",
    "# Replace `Total_Number_of_Reviews` and `Average_Score` with our own calculated values\r\n",
    "df.Total_Number_of_Reviews = df.groupby('Hotel_Name').transform('count')\r\n",
    "df.Average_Score = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Process review columns\r\n",
    "# Drop Review_Total_Negative_Word_Counts, Review_Total_Positive_Word_Counts, Review_Date and days_since_review\r\n",
    "# Keep Reviewer_Score, Negative_Review, and Positive_Review as they are,\r\n",
    "# Keep Tags for now\r\n",
    "# We'll be doing some additional filtering operations on the tags in the next section and then tags will be dropped\r\n",
    "# Process reviewer columns\r\n",
    "# Drop Total_Number_of_Reviews_Reviewer_Has_Given\r\n",
    "# Keep Reviewer_Nationality"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Remove opening and closing brackets\r\n",
    "df.Tags = df.Tags.str.strip(\"[']\")\r\n",
    "# remove all quotes too\r\n",
    "df.Tags = df.Tags.str.replace(\" ', '\", \",\", regex = False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Process the Tags into new columns\r\n",
    "# The file Hotel_Reviews_Tags.py, identifies the most important tags\r\n",
    "# Leisure trip, Couple, Solo traveler, Business trip, Group combined with Travelers with friends, \r\n",
    "# Family with young children, Family with older children, With a pet\r\n",
    "df[\"Leisure_trip\"] = df.Tags.apply(lambda tag: 1 if \"Leisure trip\" in tag else 0)\r\n",
    "df[\"Couple\"] = df.Tags.apply(lambda tag: 1 if \"Couple\" in tag else 0)\r\n",
    "df[\"Solo_traveler\"] = df.Tags.apply(lambda tag: 1 if \"Solo traveler\" in tag else 0)\r\n",
    "df[\"Business_trip\"] = df.Tags.apply(lambda tag: 1 if \"Business trip\" in tag else 0)\r\n",
    "df[\"Group\"] = df.Tags.apply(lambda tag: 1 if \"Group\" in tag or \"Travelers with friends\" in tag else 0)\r\n",
    "df[\"Family_with_young_children\"] = df.Tags.apply(lambda tag: 1 if \"Family with young children\" in tag else 0)\r\n",
    "df[\"Family_with_older_children\"] = df.Tags.apply(lambda tag: 1 if \"Family with older children\" in tag else 0)\r\n",
    "df[\"With_a_pet\"] = df.Tags.apply(lambda tag: 1 if \"With a pet\" in tag else 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df.drop([\"Review_Total_Negative_Word_Counts\", \"Review_Total_Positive_Word_Counts\", \"days_since_review\", \"Total_Number_of_Reviews_Reviewer_Has_Given\"], axis = 1, inplace=True)\r\n",
    "\r\n",
    "# Saving new data file with calculated columns\r\n",
    "print(\"Saving results to Hotel_Reviews_Filtered.csv\")\r\n",
    "df.to_csv(r'Hotel_Reviews_Filtered.csv', index = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving results to Hotel_Reviews_Filtered.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import time\r\n",
    "import pandas as pd\r\n",
    "import nltk as nltk\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
    "nltk.download('vader_lexicon')\r\n",
    "\r\n",
    "# Load the filtered hotel reviews from CSV\r\n",
    "df = pd.read_csv('Hotel_Reviews_Filtered.csv')\r\n",
    "\r\n",
    "# You code will be added here\r\n",
    "\r\n",
    "\r\n",
    "# Finally remember to save the hotel reviews with new NLP data added\r\n",
    "print(\"Saving results to Hotel_Reviews_NLP.csv\")\r\n",
    "df.to_csv(r'Hotel_Reviews_NLP.csv', index = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\AWEDA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving results to Hotel_Reviews_NLP.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from nltk.corpus import stopwords\r\n",
    "\r\n",
    "# Load the hotel reviews from CSV\r\n",
    "df = pd.read_csv(\"Hotel_Reviews_Filtered.csv\")\r\n",
    "\r\n",
    "# Remove stop words - can be slow for a lot of text!\r\n",
    "# Ryan Han (ryanxjhan on Kaggle) has a great post measuring performance of different stop words removal approaches\r\n",
    "# https://www.kaggle.com/ryanxjhan/fast-stop-words-removal # using the approach that Ryan recommends\r\n",
    "start = time.time()\r\n",
    "cache = set(stopwords.words(\"english\"))\r\n",
    "def remove_stopwords(review):\r\n",
    "    text = \" \".join([word for word in review.split() if word not in cache])\r\n",
    "    return text\r\n",
    "\r\n",
    "# Remove the stop words from both columns\r\n",
    "df.Negative_Review = df.Negative_Review.apply(remove_stopwords)   \r\n",
    "df.Positive_Review = df.Positive_Review.apply(remove_stopwords)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\AWEDA/nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\AWEDA/nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4ef78b5a34f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# https://www.kaggle.com/ryanxjhan/fast-stop-words-removal # using the approach that Ryan recommends\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{}/{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\AWEDA/nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\AWEDA\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
    "\r\n",
    "# Create the vader sentiment analyser (there are others in NLTK you can try too)\r\n",
    "vader_sentiment = SentimentIntensityAnalyzer()\r\n",
    "# Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\r\n",
    "\r\n",
    "# There are 3 possibilities of input for a review:\r\n",
    "# It could be \"No Negative\", in which case, return 0\r\n",
    "# It could be \"No Positive\", in which case, return 0\r\n",
    "# It could be a review, in which case calculate the sentiment\r\n",
    "def calc_sentiment(review):    \r\n",
    "    if review == \"No Negative\" or review == \"No Positive\":\r\n",
    "        return 0\r\n",
    "    return vader_sentiment.polarity_scores(review)[\"compound\"]    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Add a negative sentiment and positive sentiment column\r\n",
    "print(\"Calculating sentiment columns for both positive and negative reviews\")\r\n",
    "start = time.time()\r\n",
    "df[\"Negative_Sentiment\"] = df.Negative_Review.apply(calc_sentiment)\r\n",
    "df[\"Positive_Sentiment\"] = df.Positive_Review.apply(calc_sentiment)\r\n",
    "end = time.time()\r\n",
    "print(\"Calculating sentiment took \" + str(round(end - start, 2)) + \" seconds\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating sentiment columns for both positive and negative reviews\n",
      "Calculating sentiment took 475.84 seconds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df = df.sort_values(by=[\"Negative_Sentiment\"], ascending=True)\r\n",
    "print(df[[\"Negative_Review\", \"Negative_Sentiment\"]])\r\n",
    "df = df.sort_values(by=[\"Positive_Sentiment\"], ascending=True)\r\n",
    "print(df[[\"Positive_Review\", \"Positive_Sentiment\"]])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                          Negative_Review  Negative_Sentiment\n",
      "186584   So so so bad experience and memories when I w...             -0.9981\n",
      "307286   The staff Had a bad experience even after boo...             -0.9972\n",
      "201293   We are usually traveling to Paris 2 3 times a...             -0.9953\n",
      "65536    This is definitely not a four star hotel Dirt...             -0.9942\n",
      "256532   There were so many Firstly we had asked ahead...             -0.9940\n",
      "...                                                   ...                 ...\n",
      "501337   We didn t understand the term privileged room...              0.9951\n",
      "138365   Wifi was terribly slow I did a speed test on ...              0.9956\n",
      "26899    I would say however for one night it s expens...              0.9960\n",
      "480509   I travel a lot and have so far visited a coun...              0.9961\n",
      "419180   Maybe we expected too much of a classical 5 s...              0.9964\n",
      "\n",
      "[515738 rows x 2 columns]\n",
      "                                          Positive_Review  Positive_Sentiment\n",
      "373561   Reception Staff I was just a number My execut...             -0.9832\n",
      "412160   Well I arrived at 5 pm instead of 10 am due t...             -0.9828\n",
      "124178   I didnt like anythig Room too small Asked for...             -0.9806\n",
      "509568   Extremely bad service Giving impression when ...             -0.9805\n",
      "64158    when you get there everything is extra intern...             -0.9794\n",
      "...                                                   ...                 ...\n",
      "491454   We actually liked absolutely everything about...              0.9990\n",
      "180583   This modern ber cool hotel is not my normal s...              0.9991\n",
      "179007   We went to Andaz for my 40th birthday celebra...              0.9991\n",
      "405132   We came to Milano by train only for two night...              0.9992\n",
      "504735   Upon check in the staff were all so polite an...              0.9993\n",
      "\n",
      "[515738 rows x 2 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Reorder the columns (This is cosmetic, but to make it easier to explore the data later)\r\n",
    "df = df.reindex([\"Hotel_Name\", \"Hotel_Address\", \"Total_Number_of_Reviews\", \"Average_Score\", \"Reviewer_Score\", \"Negative_Sentiment\", \"Positive_Sentiment\", \"Reviewer_Nationality\", \"Leisure_trip\", \"Couple\", \"Solo_traveler\", \"Business_trip\", \"Group\", \"Family_with_young_children\", \"Family_with_older_children\", \"With_a_pet\", \"Negative_Review\", \"Positive_Review\"], axis=1)\r\n",
    "\r\n",
    "print(\"Saving results to Hotel_Reviews_NLP.csv\")\r\n",
    "df.to_csv(r\"Hotel_Reviews_NLP1.csv\", index = False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving results to Hotel_Reviews_NLP.csv\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "29bb0ae593278301629aab3376a868c27deccc17532c9747bd6d59049c818ac5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}